# BrainExplore: Large-Scale Discovery of Interpretable Visual Representations in the Human Brain

- **arXiv**: https://arxiv.org/abs/2512.08560
- **alphaXiv**: https://www.alphaxiv.org/abs/2512.08560
- **PDF**: https://arxiv.org/pdf/2512.08560.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2512.08560
- **Tags**:#visual representations #fmri analysis #automated framework
- **Added**: 2026-01-02

---

## One-liner
Understanding how the human brain represents visual concepts, and in which brain regions these representations are encoded, remains a long-standing challenge.

---

## Why I care
- なぜこの論文を読んだか

---

## Key Ideas
- Understanding how the human brain represents visual concepts, and in which brain regions these representations are encoded, remains a long-standing challenge.
- Decades of work have advanced our understanding of visual representations, yet brain signals remain large and complex, and the space of possible visual concepts is vast.
- As a result, most studies remain small-scale, rely on manual inspection, focus on specific regions and properties, and rarely include systematic validation.
- We present a large-scale, automated framework for discovering and explaining visual representations across the human cortex.

---

## Notes
Understanding how the human brain represents visual concepts, and in which brain regions these representations are encoded, remains a long-standing challenge. Decades of work have advanced our understanding of visual representations, yet brain signals remain large and complex, and the space of possible visual concepts is vast. As a result, most studies remain small-scale, rely on manual inspection, focus on specific regions and properties, and rarely include systematic validation. We present a large-scale, automated framework for discovering and explaining visual representations across the human cortex. Our method comprises two main stages. First, we discover candidate interpretable patterns in fMRI activity through unsupervised, data-driven decomposition methods. Next, we explain each pattern by identifying the set of natural images that most strongly elicit it and generating a natural-language description of their shared visual meaning. To scale this process, we introduce an automated pipeline that tests multiple candidate explanations, assigns quantitative reliability scores, and selects the most consistent description for each voxel pattern. Our framework reveals thousands of interpretable patterns spanning many distinct visual concepts, including fine-grained representations previously unreported.

---

## alphaXiv discussion memo
- 気になったコメント
- 自分の質問
