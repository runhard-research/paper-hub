# Code2World: A GUI World Model via Renderable Code Generation

- **arXiv**: https://arxiv.org/abs/2602.09856
- **alphaXiv**: https://www.alphaxiv.org/abs/2602.09856
- **PDF**: https://arxiv.org/pdf/2602.09856.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2602.09856
- **Tags**:
- **Added**: 2026-02-12

---

## One-liner
Autonomous GUI agents interact with environments by perceiving interfaces and executing actions.

---

## Why I care
- Why I read this paper

---

## Key Ideas
- However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability.
- To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation.
- Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image.

---

## Notes
Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.

---

## alphaXiv discussion memo
- Comments that caught my attention
- A question I have
