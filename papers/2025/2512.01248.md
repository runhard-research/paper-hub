# TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition

- **arXiv**: https://arxiv.org/abs/2512.01248
- **alphaXiv**: https://www.alphaxiv.org/abs/2512.01248
- **PDF**: https://arxiv.org/pdf/2512.01248.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2512.01248
- **Tags**:#table recognition #self-supervised learning #vision-language models
- **Added**: 2026-01-02

---

## One-liner
Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown.

---

## Why I care
- なぜこの論文を読んだか

---

## Key Ideas
- Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown.
- To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild.
- An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model.
- Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks.

---

## Notes
Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have continuously pushed the performance boundary, open-source models, often trained with limited resources and, in practice, the only viable option for many due to privacy regulations, still lag far behind. To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild. Built upon Group Relative Policy Optimization, TRivia automatically identifies unlabeled samples that most effectively facilitate learning and eliminates the need for human annotations through a question-answering-based reward mechanism. An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model. This closed-loop process allows the TR model to autonomously learn to recognize, structure, and reason over tables without labeled data. Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks. Model and code are released at: https://github.com/opendatalab/TRivia

---

## alphaXiv discussion memo
- 気になったコメント
- 自分の質問
