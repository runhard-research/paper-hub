# NVIDIA Nemotron Parse 1.1

- **arXiv**: https://arxiv.org/abs/2511.20478
- **alphaXiv**: https://www.alphaxiv.org/abs/2511.20478
- **PDF**: https://arxiv.org/pdf/2511.20478.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2511.20478
- **Tags**:#nemotron-parse-1.1 #ocr model #document parsing
- **Added**: 2026-01-02

---

## One-liner
We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0.

---

## Why I care
- なぜこの論文を読んだか

---

## Key Ideas
- We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0.
- It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution.

---

## Notes
We introduce Nemotron-Parse-1.1, a lightweight document parsing and OCR model that advances the capabilities of its predecessor, Nemoretriever-Parse-1.0. Nemotron-Parse-1.1 delivers improved capabilities across general OCR, markdown formatting, structured table parsing, and text extraction from pictures, charts, and diagrams. It also supports a longer output sequence length for visually dense documents. As with its predecessor, it extracts bounding boxes of text segments, as well as corresponding semantic classes. Nemotron-Parse-1.1 follows an encoder-decoder architecture with 885M parameters, including a compact 256M-parameter language decoder. It achieves competitive accuracy on public benchmarks making it a strong lightweight OCR solution. We release the model weights publicly on Huggingface, as well as an optimized NIM container, along with a subset of the training data as part of the broader Nemotron-VLM-v2 dataset. Additionally, we release Nemotron-Parse-1.1-TC which operates on a reduced vision token length, offering a 20% speed improvement with minimal quality degradation.

---

## alphaXiv discussion memo
- 気になったコメント
- 自分の質問
