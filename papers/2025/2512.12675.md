# Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling

- **arXiv**: https://arxiv.org/abs/2512.12675
- **alphaXiv**: https://www.alphaxiv.org/abs/2512.12675
- **PDF**: https://arxiv.org/pdf/2512.12675.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2512.12675
- **Tags**:#image generation #multi-subject composition #semantic alignment
- **Added**: 2026-01-02

---

## One-liner
Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates.

---

## Why I care
- なぜこの論文を読んだか

---

## Key Ideas
- We propose Scone, a unified understanding-generation method that integrates composition and distinction.
- We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios.
- Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks.

---

## Notes
Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone.

---

## alphaXiv discussion memo
- 気になったコメント
- 自分の質問
