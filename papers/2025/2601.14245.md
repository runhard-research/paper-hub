# XR: Cross-Modal Agents for Composed Image Retrieval

- **arXiv**: https://arxiv.org/abs/2601.14245
- **alphaXiv**: https://www.alphaxiv.org/abs/2601.14245
- **PDF**: https://arxiv.org/pdf/2601.14245.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2601.14245
- **Tags**:
- **Added**: 2026-01-23

---

## One-liner
Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms.

---

## Why I care
- Why I read this paper

---

## Key Ideas
- While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning.
- To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process.
- It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering.
- Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential.

---

## Notes
Retrieval is being redefined by agentic AI, demanding multimodal reasoning beyond conventional similarity-based paradigms. Composed Image Retrieval (CIR) exemplifies this shift as each query combines a reference image with textual modifications, requiring compositional understanding across modalities. While embedding-based CIR methods have achieved progress, they remain narrow in perspective, capturing limited cross-modal cues and lacking semantic reasoning. To address these limitations, we introduce XR, a training-free multi-agent framework that reframes retrieval as a progressively coordinated reasoning process. It orchestrates three specialized types of agents: imagination agents synthesize target representations through cross-modal generation, similarity agents perform coarse filtering via hybrid matching, and question agents verify factual consistency through targeted reasoning for fine filtering. Through progressive multi-agent coordination, XR iteratively refines retrieval to meet both semantic and visual query constraints, achieving up to a 38% gain over strong training-free and training-based baselines on FashionIQ, CIRR, and CIRCO, while ablations show each agent is essential. Code is available: https://01yzzyu.github.io/xr.github.io/.

---

## alphaXiv discussion memo
- Comments that caught my attention
- A question I have
