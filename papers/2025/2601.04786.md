# AgentOCR: Reimagining Agent History via Optical Self-Compression

- **arXiv**: https://arxiv.org/abs/2601.04786
- **alphaXiv**: https://www.alphaxiv.org/abs/2601.04786
- **PDF**: https://arxiv.org/pdf/2601.04786.pdf
- **HuggingFace Papers**: https://huggingface.co/papers/2601.04786
- **Tags**:
- **Added**: 2026-01-13

---

## One-liner
Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage.

---

## Why I care
- Why I read this paper

---

## Key Ideas
- We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image.
- To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching.
- Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency.
- We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA.

---

## Notes
Recent advances in large language models (LLMs) enable agentic systems trained with reinforcement learning (RL) over multi-turn interaction trajectories, but practical deployment is bottlenecked by rapidly growing textual histories that inflate token budgets and memory usage. We introduce AgentOCR, a framework that exploits the superior information density of visual tokens by representing the accumulated observation-action history as a compact rendered image. To make multi-turn rollouts scalable, AgentOCR proposes segment optical caching. By decomposing history into hashable segments and maintaining a visual cache, this mechanism eliminates redundant re-rendering. Beyond fixed rendering, AgentOCR introduces agentic self-compression, where the agent actively emits a compression rate and is trained with compression-aware reward to adaptively balance task success and token efficiency. We conduct extensive experiments on challenging agentic benchmarks, ALFWorld and search-based QA. Remarkably, results demonstrate that AgentOCR preserves over 95\% of text-based agent performance while substantially reducing token consumption (>50\%), yielding consistent token and memory efficiency. Our further analysis validates a 20x rendering speedup from segment optical caching and the effective strategic balancing of self-compression.

---

## alphaXiv discussion memo
- Comments that caught my attention
- A question I have
